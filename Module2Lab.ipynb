{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c75f6a-2a9f-471f-9c8d-afd6562e155c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import zipfile\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To ignore some warnings about Image metadata that Pillow prints out\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b51a13-0fa0-4d60-82a7-bcef7efde5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "import wget\n",
    "\n",
    "# Cats and dogs\n",
    "!wget https://storage.googleapis.com/mlep-public/course_1/week2/kagglecatsanddogs_3367a.zip\n",
    "\n",
    "# Caltech birds\n",
    "!wget https://storage.googleapis.com/mlep-public/course_1/week2/CUB_200_2011.tar\n",
    "\n",
    "# Download pretrained models and training histories\n",
    "!wget -q -P ./model-balanced/ https://storage.googleapis.com/mlep-public/course_1/week2/model-balanced/saved_model.pb\n",
    "!wget -q -P ./model-balanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-balanced/variables/variables.data-00000-of-00001\n",
    "!wget -q -P ./model-balanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-balanced/variables/variables.index\n",
    "!wget -q -P ./history-balanced/ https://storage.googleapis.com/mlep-public/course_1/week2/history-balanced/history-balanced.csv\n",
    "\n",
    "!wget -q -P ./model-imbalanced/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/saved_model.pb\n",
    "!wget -q -P ./model-imbalanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/variables/variables.data-00000-of-00001\n",
    "!wget -q -P ./model-imbalanced/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/variables/variables.index\n",
    "!wget -q -P ./history-imbalanced/ https://storage.googleapis.com/mlep-public/course_1/week2/history-imbalanced/history-imbalanced.csv\n",
    "\n",
    "!wget -q -P ./model-augmented/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/saved_model.pb\n",
    "!wget -q -P ./model-augmented/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.data-00000-of-00001\n",
    "!wget -q -P ./model-augmented/variables/ https://storage.googleapis.com/mlep-public/course_1/week2/model-augmented/variables/variables.index\n",
    "!wget -q -P ./history-augmented/ https://storage.googleapis.com/mlep-public/course_1/week2/history-augmented/history-augmented.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ad69b1-7c0a-4430-82de-58ba3888b975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cats_and_dogs_zip = './kagglecatsanddogs_3367a.zip'\n",
    "caltech_birds_tar = './CUB_200_2011.tar'\n",
    "\n",
    "base_dir = '/tmp/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2717a-0c7d-40a3-8884-3daf9aae0269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(cats_and_dogs_zip, 'r') as my_zip:\n",
    "  my_zip.extractall(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0d93f-204a-4ec2-ae4c-88f1019cfd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tarfile.open(caltech_birds_tar, 'r') as my_tar:\n",
    "  my_tar.extractall(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f843e-6f09-446a-973a-dd3bc215bd24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dogs_dir = os.path.join(base_dir, 'PetImages/Dog')\n",
    "base_cats_dir = os.path.join(base_dir,'PetImages/Cat')\n",
    "\n",
    "print(f\"There are {len(os.listdir(base_dogs_dir))} images of dogs\")\n",
    "print(f\"There are {len(os.listdir(base_cats_dir))} images of cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd42980-dd70-412a-9f18-78d3c2f955ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_birds_dir = '/tmp/data/CUB_200_2011/images'\n",
    "base_birds_dir = os.path.join(base_dir,'PetImages/Bird')\n",
    "os.mkdir(base_birds_dir)\n",
    "\n",
    "for subdir in os.listdir(raw_birds_dir):\n",
    "  subdir_path = os.path.join(raw_birds_dir, subdir)\n",
    "  for image in os.listdir(subdir_path):\n",
    "    shutil.move(os.path.join(subdir_path, image), os.path.join(base_birds_dir))\n",
    "\n",
    "print(f\"There are {len(os.listdir(base_birds_dir))} images of birds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69802a6c-9a3e-4762-a226-ffe171590a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"Sample cat image:\")\n",
    "display(Image(filename=f\"{os.path.join(base_cats_dir, os.listdir(base_cats_dir)[0])}\"))\n",
    "print(\"\\nSample dog image:\")\n",
    "display(Image(filename=f\"{os.path.join(base_dogs_dir, os.listdir(base_dogs_dir)[0])}\"))\n",
    "print(\"\\nSample bird image:\")\n",
    "display(Image(filename=f\"{os.path.join(base_birds_dir, os.listdir(base_birds_dir)[0])}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0e028e-83ec-484e-b4f9-5f1d596e2f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_eval_dirs = ['train/cats', 'train/dogs', 'train/birds',\n",
    "                   'eval/cats', 'eval/dogs', 'eval/birds']\n",
    "\n",
    "for dir in train_eval_dirs:\n",
    "  if not os.path.exists(os.path.join(base_dir, dir)):\n",
    "    os.makedirs(os.path.join(base_dir, dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45401c28-a15c-438b-8102-9f5c99220e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def move_to_destination(origin, destination, percentage_split):\n",
    "  num_images = int(len(os.listdir(origin))*percentage_split)\n",
    "  for image_name, image_number in zip(sorted(os.listdir(origin)), range(num_images)):\n",
    "    shutil.move(os.path.join(origin, image_name), destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e2bc8-c678-44aa-a771-22e2ec5d91ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Move 70% of the images to the train dir\n",
    "move_to_destination(base_cats_dir, os.path.join(base_dir, 'train/cats'), 0.7)\n",
    "move_to_destination(base_dogs_dir, os.path.join(base_dir, 'train/dogs'), 0.7)\n",
    "move_to_destination(base_birds_dir, os.path.join(base_dir, 'train/birds'), 0.7)\n",
    "\n",
    "\n",
    "# Move the remaining images to the eval dir\n",
    "move_to_destination(base_cats_dir, os.path.join(base_dir, 'eval/cats'), 1)\n",
    "move_to_destination(base_dogs_dir, os.path.join(base_dir, 'eval/dogs'), 1)\n",
    "move_to_destination(base_birds_dir, os.path.join(base_dir, 'eval/birds'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e40d0-85c8-4362-b59d-5ccf82f3fd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!find /tmp/data/ -size 0 -exec rm {} +\n",
    "!find /tmp/data/ -type f ! -name \"*.jpg\" -exec rm {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e329903-f625-434a-aab1-d63a7aa995d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'train/cats')))} images of cats for training\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'train/dogs')))} images of dogs for training\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'train/birds')))} images of birds for training\\n\")\n",
    "\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'eval/cats')))} images of cats for evaluation\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'eval/dogs')))} images of dogs for evaluation\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'eval/birds')))} images of birds for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983d408-7c40-4c17-9095-9b19a5670126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dir in train_eval_dirs:\n",
    "  if not os.path.exists(os.path.join(base_dir, 'imbalanced/'+dir)):\n",
    "    os.makedirs(os.path.join(base_dir, 'imbalanced/'+dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02df8ca-a49d-4d92-a441-f8b613beda8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Very similar to the one used before but this one copies instead of moving\n",
    "def copy_with_limit(origin, destination, percentage_split):\n",
    "  num_images = int(len(os.listdir(origin))*percentage_split)\n",
    "  for image_name, image_number in zip(sorted(os.listdir(origin)), range(num_images)):\n",
    "    shutil.copy(os.path.join(origin, image_name), destination)\n",
    "\n",
    "# Perform the copying\n",
    "copy_with_limit(os.path.join(base_dir, 'train/cats'), os.path.join(base_dir, 'imbalanced/train/cats'), 1)\n",
    "copy_with_limit(os.path.join(base_dir, 'train/dogs'), os.path.join(base_dir, 'imbalanced/train/dogs'), 0.2)\n",
    "copy_with_limit(os.path.join(base_dir, 'train/birds'), os.path.join(base_dir, 'imbalanced/train/birds'), 0.1)\n",
    "\n",
    "copy_with_limit(os.path.join(base_dir, 'eval/cats'), os.path.join(base_dir, 'imbalanced/eval/cats'), 1)\n",
    "copy_with_limit(os.path.join(base_dir, 'eval/dogs'), os.path.join(base_dir, 'imbalanced/eval/dogs'), 0.2)\n",
    "copy_with_limit(os.path.join(base_dir, 'eval/birds'), os.path.join(base_dir, 'imbalanced/eval/birds'), 0.1)\n",
    "\n",
    "# Print number of available images\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'imbalanced/train/cats')))} images of cats for training\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'imbalanced/train/dogs')))} images of dogs for training\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'imbalanced/train/birds')))} images of birds for training\\n\")\n",
    "\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'imbalanced/eval/cats')))} images of cats for evaluation\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'imbalanced/eval/dogs')))} images of dogs for evaluation\")\n",
    "print(f\"There are {len(os.listdir(os.path.join(base_dir, 'imbalanced/eval/birds')))} images of birds for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ef344-e93f-4be5-8eca-41d3320ed3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def create_model():\n",
    "  # A simple CNN architecture based on the one found here: https://www.tensorflow.org/tutorials/images/classification\n",
    "  model = models.Sequential([\n",
    "  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2, 2)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "  ])\n",
    "\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      #optimizer=optimizers.Adam(),\n",
    "      optimizer=optimizers.legacy.Adam(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd3350-8b4f-4c2c-9d14-31cd15618441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model to use with the imbalanced dataset\n",
    "imbalanced_model = create_model()\n",
    "\n",
    "# Print the model's summary\n",
    "print(imbalanced_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b564d8-84d7-4ade-aeaa-30a7e73c9900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# No data augmentation for now, only normalizing pixel values\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Point to the imbalanced directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/tmp/data/imbalanced/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/tmp/data/imbalanced/eval',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a994d-d6c7-4301-b566-e76f8ae78f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"labels for each class in the train generator are: {train_generator.class_indices}\")\n",
    "print(f\"labels for each class in the validation generator are: {validation_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0b0ff-b5c0-48c0-9dbb-c843d517fdf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q -P ./history-imbalanced/ https://storage.googleapis.com/mlep-public/course_1/week2/history-imbalanced/history-imbalanced.csv\n",
    "\n",
    "!wget -q -P ./model-imbalanced/ https://storage.googleapis.com/mlep-public/course_1/week2/model-imbalanced/saved_model.pb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838c6e4-03c2-46c6-b7e0-8000a06f5fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pretrained model and history\n",
    "\n",
    "imbalanced_history = pd.read_csv('./history-imbalanced/history-imbalanced.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fcb2b-747c-4bf3-b96c-e5da387ce5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imbalanced_model = tf.keras.models.load_model('./model-imbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be182cb-070a-4f1f-b8ea-993d0b666902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imbalanced_history = imbalanced_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d9e6f-1c30-4c31-95f5-7befb3e89ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_metrics(history):\n",
    "  \n",
    "  # This is needed depending on if you used the pretrained model or you trained it yourself\n",
    "  if not isinstance(history, pd.core.frame.DataFrame):\n",
    "    history = history.history\n",
    "  \n",
    "  acc = history['sparse_categorical_accuracy']\n",
    "  val_acc = history['val_sparse_categorical_accuracy']\n",
    "\n",
    "  loss = history['loss']\n",
    "  val_loss = history['val_loss']\n",
    "\n",
    "  return acc, val_acc, loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a382a4-ebab-4e4c-8a8e-b18c0379bb99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_train_eval(history):\n",
    "  acc, val_acc, loss, val_loss = get_training_metrics(history)\n",
    "\n",
    "  acc_plot = pd.DataFrame({\"training accuracy\":acc, \"evaluation accuracy\":val_acc})\n",
    "  acc_plot = sns.lineplot(data=acc_plot)\n",
    "  acc_plot.set_title('training vs evaluation accuracy')\n",
    "  acc_plot.set_xlabel('epoch')\n",
    "  acc_plot.set_ylabel('sparse_categorical_accuracy')\n",
    "  plt.show()\n",
    "\n",
    "  print(\"\")\n",
    "\n",
    "  loss_plot = pd.DataFrame({\"training loss\":loss, \"evaluation loss\":val_loss})\n",
    "  loss_plot = sns.lineplot(data=loss_plot)\n",
    "  loss_plot.set_title('training vs evaluation loss')\n",
    "  loss_plot.set_xlabel('epoch')\n",
    "  loss_plot.set_ylabel('loss')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_train_eval(imbalanced_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab26c854-f9ea-4a46-9e7b-22da44665831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, balanced_accuracy_score\n",
    "# Use the validation generator without shuffle to easily compute additional metrics\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/imbalanced/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed7b97-6d8e-4b99-a5f9-2cc0440c63b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the true labels from the generator\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "# Use the model to predict (will take a couple of minutes)\n",
    "predictions_imbalanced = imbalanced_model.predict(val_gen_no_shuffle)\n",
    "\n",
    "# Get the argmax (since softmax is being used)\n",
    "y_pred_imbalanced = np.argmax(predictions_imbalanced, axis=1)\n",
    "\n",
    "# Print accuracy score\n",
    "print(f\"Accuracy Score: {accuracy_score(y_true, y_pred_imbalanced)}\")\n",
    "\n",
    "# Print balanced accuracy score\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_true, y_pred_imbalanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9763f-2571-465b-97a4-9b37ea489aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imbalanced_cm = confusion_matrix(y_true, y_pred_imbalanced)\n",
    "ConfusionMatrixDisplay(imbalanced_cm, display_labels=['birds', 'cats', 'dogs']).plot(values_format=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd4129-1bf6-480c-ade3-4920e5fb4fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "misclassified_birds = (imbalanced_cm[0, 1] + imbalanced_cm[0, 2])/np.sum(imbalanced_cm, axis=1)[0]\n",
    "misclassified_cats = (imbalanced_cm[1, 0] + imbalanced_cm[1, 2])/np.sum(imbalanced_cm, axis=1)[1]\n",
    "misclassified_dogs = (imbalanced_cm[2, 0] + imbalanced_cm[2, 1])/np.sum(imbalanced_cm, axis=1)[2]\n",
    "\n",
    "print(f\"Proportion of misclassified birds: {misclassified_birds*100:.2f}%\")\n",
    "print(f\"Proportion of misclassified cats: {misclassified_cats*100:.2f}%\")\n",
    "print(f\"Proportion of misclassified dogs: {misclassified_dogs*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f20c9f-0457-4015-9ed6-5d05f40d3709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict cat for all images\n",
    "all_cats = np.ones(y_true.shape)\n",
    "\n",
    "# Print accuracy score\n",
    "print(f\"Accuracy Score: {accuracy_score(y_true, all_cats)}\")\n",
    "\n",
    "# Print balanced accuracy score\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_true, all_cats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08075ec2-0e6b-491a-aaad-cf663bf228f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the validation generator without shuffle to easily compute additional metrics\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False)\n",
    "\n",
    "# Get the true labels from the generator\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "# Use the model to predict (will take a couple of minutes)\n",
    "predictions_imbalanced = imbalanced_model.predict(val_gen_no_shuffle)\n",
    "\n",
    "# Get the argmax (since softmax is being used)\n",
    "y_pred_imbalanced = np.argmax(predictions_imbalanced, axis=1)\n",
    "\n",
    "# Confusion matrix\n",
    "imbalanced_cm = confusion_matrix(y_true, y_pred_imbalanced)\n",
    "ConfusionMatrixDisplay(imbalanced_cm, display_labels=['birds', 'cats', 'dogs']).plot(values_format=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b647f-3e80-4f85-8824-94cd11094426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "misclassified_birds = (imbalanced_cm[0, 1] + imbalanced_cm[0, 2])/np.sum(imbalanced_cm, axis=1)[0]\n",
    "misclassified_cats = (imbalanced_cm[1, 0] + imbalanced_cm[1, 2])/np.sum(imbalanced_cm, axis=1)[1]\n",
    "misclassified_dogs = (imbalanced_cm[2, 0] + imbalanced_cm[2, 1])/np.sum(imbalanced_cm, axis=1)[2]\n",
    "\n",
    "print(f\"Proportion of misclassified birds: {misclassified_birds*100:.2f}%\")\n",
    "print(f\"Proportion of misclassified cats: {misclassified_cats*100:.2f}%\")\n",
    "print(f\"Proportion of misclassified dogs: {misclassified_dogs*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c149d71-fcdb-4de0-ba0b-15e961dec43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model to use with the balanced dataset\n",
    "balanced_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc82255-adde-4300-b02c-add16a9803a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Still no data augmentation, only re-scaling\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generators now point to the complete dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/tmp/data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/tmp/data/eval',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db2ce7-3240-4b62-b3f3-301ecd928b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pretrained model and history\n",
    "\n",
    "balanced_history = pd.read_csv('history-balanced/history-balanced.csv')\n",
    "balanced_model = tf.keras.models.load_model('model-balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f53d60-7709-4e59-935f-844ba56c7c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run only if you want to train the model yourself (this takes around 20 mins with GPU enabled)\n",
    "\n",
    "balanced_history = balanced_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5956c4d-e3be-4e3c-a963-1f2de5a2f9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the validation generator without shuffle to easily compute additional metrics\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae28e99-6ea8-4810-9b6b-36d5886a0782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the true labels from the generator\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "# Use the model to predict (will take a couple of minutes)\n",
    "predictions_balanced = balanced_model.predict(val_gen_no_shuffle)\n",
    "\n",
    "# Get the argmax (since softmax is being used)\n",
    "y_pred_balanced = np.argmax(predictions_balanced, axis=1)\n",
    "\n",
    "# Print accuracy score\n",
    "print(f\"Accuracy Score: {accuracy_score(y_true, y_pred_balanced)}\")\n",
    "\n",
    "# Print balanced accuracy score\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_true, y_pred_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6f2ff-246d-4da1-91ba-30e5962bf7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_cm = confusion_matrix(y_true, y_pred_balanced)\n",
    "ConfusionMatrixDisplay(balanced_cm, display_labels=['birds', 'cats', 'dogs']).plot(values_format=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30e32f-6d33-4d1e-9cf1-e01c56a4073c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_train_eval(balanced_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4096526-8f0e-428e-b05a-97a8eeb7e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model to use with the balanced dataset\n",
    "balanced_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d6fab-51f8-461e-b675-92caf0fc8aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Still no data augmentation, only re-scaling\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generators now point to the complete dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/tmp/data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/tmp/data/eval',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd25448-7764-487f-8ed7-8da9835f2b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pretrained model and history\n",
    "\n",
    "balanced_history = pd.read_csv('history-balanced/history-balanced.csv')\n",
    "balanced_model = tf.keras.models.load_model('model-balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b293c8-2ccc-4ecc-a2cc-aeb86293e80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run only if you want to train the model yourself (this takes around 20 mins with GPU enabled)\n",
    "\n",
    "balanced_history = balanced_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd5e78-d078-4232-b46c-8b7e32921605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the validation generator without shuffle to easily compute additional metrics\n",
    "val_gen_no_shuffle = test_datagen.flow_from_directory(\n",
    "    '/tmp/data/eval',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68db57a-ce8a-4571-ab97-80796f1f0cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the true labels from the generator\n",
    "y_true = val_gen_no_shuffle.classes\n",
    "\n",
    "# Use the model to predict (will take a couple of minutes)\n",
    "predictions_balanced = balanced_model.predict(val_gen_no_shuffle)\n",
    "\n",
    "# Get the argmax (since softmax is being used)\n",
    "y_pred_balanced = np.argmax(predictions_balanced, axis=1)\n",
    "\n",
    "# Print accuracy score\n",
    "print(f\"Accuracy Score: {accuracy_score(y_true, y_pred_balanced)}\")\n",
    "\n",
    "# Print balanced accuracy score\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_true, y_pred_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207a9af-56d5-428b-b9a2-d86cd1090f22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_cm = confusion_matrix(y_true, y_pred_balanced)\n",
    "ConfusionMatrixDisplay(balanced_cm, display_labels=['birds', 'cats', 'dogs']).plot(values_format=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267c913-ce6c-4f8e-8684-42ad9b3b631c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_train_eval(balanced_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d8dbb-85b5-4145-be9c-78a5858c50f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model to use with the balanced and augmented dataset\n",
    "augmented_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc5089-70d8-46c8-b2c7-addb8c795f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now applying image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=50,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Still pointing to directory with full dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/tmp/data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/tmp/data/eval',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='sparse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b3488-f3eb-449c-9111-6712564447eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, load_img\n",
    "\n",
    "\n",
    "# Displays transformations on random images of birds in the training partition\n",
    "def display_transformations(gen):\n",
    "  train_birds_dir = \"/tmp/data/train/birds\"\n",
    "  random_index = random.randint(0, len(os.listdir(train_birds_dir)))\n",
    "  sample_image = load_img(f\"{os.path.join(train_birds_dir, os.listdir(train_birds_dir)[random_index])}\", target_size=(150, 150))\n",
    "  sample_array = img_to_array(sample_image)\n",
    "  sample_array = sample_array[None, :]\n",
    "\n",
    "\n",
    "  for iteration, array in zip(range(4), gen.flow(sample_array, batch_size=1)):\n",
    "    array = np.squeeze(array)\n",
    "    img = array_to_img(array)\n",
    "    print(f\"\\nTransformation number: {iteration}\\n\")\n",
    "    display(img)\n",
    "\n",
    "\n",
    "# An example of an ImageDataGenerator\n",
    "sample_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=50,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "display_transformations(sample_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47b317-eb9f-46b3-881d-d7f5e90ef3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An ImageDataGenerator with more extreme data augmentation\n",
    "sample_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=0.5,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "display_transformations(sample_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
